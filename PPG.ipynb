{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled6.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "ouKtewz_oDjU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Importing andpreprosessing data"
      ]
    },
    {
      "metadata": {
        "id": "JfoGDwXqR4n5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import io\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ebJ5EePnjaSO",
        "colab_type": "code",
        "outputId": "915f3859-a753-4ca6-8843-ba070130a8e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "cell_type": "code",
      "source": [
        "import io\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "#X_train\n",
        "from random import sample\n",
        "y_feature_train =  pd.read_csv('xlabel.csv')\n",
        "print(y_feature_train.shape)\n",
        "#folder=pd.get_dummies(y_feature_train.iloc[:,1])\n",
        "label=y_feature_train.iloc[:,19]#label : 1 denotes  high blood\n",
        "\n",
        "y_feature_train1 =  pd.read_csv('xtlabel.csv')\n",
        "print(y_feature_train1.shape)\n",
        "\n",
        "label1=y_feature_train1.iloc[:,19]#label : 1 \n",
        "y_feature_train=np.concatenate((y_feature_train,y_feature_train1),axis=0)\n",
        "label=np.concatenate((label,label1),axis=0)\n",
        "folder=y_feature_train[:,1]\n",
        "folder=pd.get_dummies(folder)\n",
        "folder=np.array(folder)\n",
        "label=label.reshape(label.shape[0],1)\n",
        "label=label.astype(np.float32)\n",
        "#TEST SAMPLES ON THE SAME PATIENTS\n",
        "n = range(label.shape[0])\n",
        "l=[]\n",
        "for i in range(folder.shape[-1]):\n",
        "    \n",
        "    s=np.array(n)[(folder[:,i])>0]\n",
        "    S=sample(list(s),1)\n",
        "    l.append(S)\n",
        "\n",
        "l=np.array(l).reshape(len(l),)   \n",
        "l#test sample\n",
        "left=np.setdiff1d(n, l)#train number\n",
        "labeltrain=label[left,]\n",
        "t=labeltrain>0\n",
        "t=t.reshape(t.shape[0],)\n",
        "print(labeltrain.shape)\n",
        "labeltrain.shape\n",
        "labeltrain=np.concatenate((labeltrain,labeltrain[t,],labeltrain[t,],labeltrain[t,],labeltrain[t,]),axis=0)\n",
        "print(labeltrain.shape)\n",
        "labeltest=label[l,:]\n",
        "print(labeltest.shape)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4009, 26)\n",
            "(2589, 26)\n",
            "(6022, 1)\n",
            "(11522, 1)\n",
            "(576, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-anbBjdokEFY",
        "colab_type": "code",
        "outputId": "763c1e4f-a60a-489e-fe9c-137d8d9a712d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "f=open('train.txt','rb')\n",
        "\n",
        "X=pickle.load(f)\n",
        "\n",
        "f.close()\n",
        "X=X[:,:,[0]]\n",
        "X.shape\n",
        "\n",
        "import pickle\n",
        "ll=open('DATATrain.txt','rb')\n",
        "X1=pickle.load(ll)\n",
        "ll.close()\n",
        "X=np.concatenate((X,X1),axis=0)\n",
        "X_train=X[left,0:256,]\n",
        "x1=X[left,256:512,][t,]\n",
        "x2=X[left,512:768,][t,]\n",
        "x3=X[left,768:1024,][t,]\n",
        "x4=X[left,1024:1280,][t,]\n",
        "#print(x2.shape)\n",
        "\n",
        "X_test=X[l,0:256,]#.reshape(339,384,1)\n",
        "X_train=np.concatenate((X_train,x1,x2,x3,x4),axis=0)\n",
        "#X_train=X_train.reshape(X_train.shape[0],384,1)\n",
        "#X_test.shape\n",
        "print(X_test.shape)\n",
        "print(X_train.shape)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(576, 256, 1)\n",
            "(11522, 256, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "k-8K_vhNkQ8d",
        "colab_type": "code",
        "outputId": "c9b8723b-9839-4161-aa82-ca520808d0a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "cell_type": "code",
      "source": [
        "#foldertrain=folder[left,]\n",
        "gender=pd.get_dummies(y_feature_train[:,12])\n",
        "position=pd.get_dummies(y_feature_train[:,11])\n",
        "drug=pd.get_dummies(y_feature_train[:,16])\n",
        "cali=pd.get_dummies(y_feature_train[:,18])\n",
        "a=[13,14,15]\n",
        "feature3=y_feature_train[:, a]# delete idx\n",
        "#frames=[feature3,folder,drug,cali,gender,position]\n",
        "frames=[feature3,drug.iloc[:,[0]],cali.iloc[:,[0]],gender.iloc[:,[0]],position.iloc[:,0:2]]\n",
        "feature=np.concatenate(frames,axis=1)\n",
        "#idn=np.array(y_feature_train.iloc[:,0])\n",
        "#feature=np.array(feature3)\n",
        "feature[:,0:3]=preprocessing.scale(feature[:,0:3])\n",
        "#feature[0,]\n",
        "print(feature[0,])\n",
        "featuretrain=feature[left,]\n",
        "featuretrain=np.concatenate((featuretrain,featuretrain[t,],featuretrain[t,],featuretrain[t,],featuretrain[t,]),axis=0)\n",
        "featuretest=feature[l,]\n",
        "foldertrain=folder[left,]\n",
        "foldertrain=np.concatenate((foldertrain,foldertrain[t,],foldertrain[t,],foldertrain[t,],foldertrain[t,]),axis=0)\n",
        "foldertest=folder[l,]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.18798878391209561 0.6666484414541839 0.5781951841194121 1 0 0 1 0]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
            "  warnings.warn(msg, DataConversionWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "_LMYZiy8oVNj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training data"
      ]
    },
    {
      "metadata": {
        "id": "M21NcWhqRPf3",
        "colab_type": "code",
        "outputId": "6a349eab-fdfb-4e63-a7a5-29582616bea7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "cell_type": "code",
      "source": [
        "#X=featuretrain\n",
        "X=np.concatenate((np.ones((featuretrain.shape[0],1)),featuretrain),axis=1).astype(float)\n",
        "Y=labeltrain.reshape(labeltrain.shape[0],)# reshape label (N,)\n",
        "Z=foldertrain\n",
        "print(X.shape)\n",
        "print(Y.shape)\n",
        "print(Z.shape)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11522, 9)\n",
            "(11522,)\n",
            "(11522, 576)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4_eGB8igfqsb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Testing data"
      ]
    },
    {
      "metadata": {
        "id": "9hQoIAXFfo7L",
        "colab_type": "code",
        "outputId": "be628018-4dda-4512-b3c6-d7d82f06dcd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "Ytest=labeltest.reshape(labeltest.shape[0],)\n",
        "Xtest=np.concatenate((np.ones((featuretest.shape[0],1)),featuretest),axis=1).astype(float)\n",
        "Ztest=foldertest\n",
        "#X_test #ppg signal\n",
        "print(Ytest.shape,Xtest.shape,Ztest.shape)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(576,) (576, 9) (576, 576)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kj0iuFqPESfi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Section1 CNN combined with mixed logistic regression\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "Wgg8VA30n5kK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1.1CNN structure"
      ]
    },
    {
      "metadata": {
        "id": "lM4XDq8ckbKV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "def bn(inputsx,in_size,decay_rate,on_train):\n",
        "    fc_mean, fc_var = tf.nn.moments(\n",
        "\n",
        "                inputsx,\n",
        "\n",
        "                axes=[0],   \n",
        "            )\n",
        "    scale = tf.Variable(tf.ones([in_size]))\n",
        "\n",
        "    shift = tf.Variable(tf.zeros([in_size]))\n",
        "\n",
        "    epsilon = 0.001\n",
        "\n",
        "\n",
        "\n",
        "            # apply moving average for mean and var when train on batch\n",
        "\n",
        "    ema = tf.train.ExponentialMovingAverage(decay=decay_rate)\n",
        "\n",
        "    def mean_var_with_update():\n",
        "        ema_apply_op = ema.apply([fc_mean, fc_var])\n",
        "        with tf.control_dependencies([ema_apply_op]):\n",
        "            return tf.identity(fc_mean), tf.identity(fc_var)\n",
        "\n",
        "    mean, var = tf.cond(on_train,    # on_train 的值是 True/False\n",
        "            mean_var_with_update,   # 如果是 True, 更新 mean/var\n",
        "            lambda: (               # 如果是 False, 返回之前 fc_mean/fc_var 的Moving Average\n",
        "                ema.average(fc_mean), \n",
        "                ema.average(fc_var)\n",
        "                )    \n",
        "            )\n",
        "    bn_learner = tf.nn.batch_normalization(inputsx, mean, var, shift, scale, epsilon)\n",
        "    return bn_learner"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YmoZEC0YkhnN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "n_channels = 1\n",
        "\n",
        "seq_len =   256     # Number   time sequence\n",
        "lr = 0.0001\n",
        "epochs = 40\n",
        "keep_prob_=0.5\n",
        "de_rate=0.5\n",
        "K_size=12#kernal size\n",
        "inputs_ = tf.placeholder(tf.float32, [None, seq_len, n_channels], name = 'inputs')\n",
        "Y_ = tf.placeholder(tf.float32, [None, 1], name = 'y')\n",
        "#feature_ = tf.placeholder(tf.float32, [None, 12], name = 'features')\n",
        "tf_is_training = tf.placeholder(tf.bool, None)  # to control dropout when training and testing"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H-oOyBOCkoEm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def layer(inputss,n_out):\n",
        "    conv1 = tf.layers.conv1d(inputs=inputss, filters=n_out, kernel_size=K_size, strides=1, \n",
        "                             padding='same', activation = None)\n",
        "    bn_layer1=bn(conv1,n_out,de_rate,tf_is_training)\n",
        "    relu1=tf.nn.relu(bn_layer1)\n",
        "    max_pool_1 = tf.layers.max_pooling1d(inputs=relu1, pool_size=K_size, strides=2, padding='same')\n",
        "    return max_pool_1\n",
        "layer1=layer(inputs_,8)\n",
        "layer2=layer(layer1,8)\n",
        "layer3=layer(layer2,16)  \n",
        "layer4=layer(layer3,16) \n",
        "#layer5=layer(layer4,32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n4kX4m_2kvX2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "flat = tf.reshape(layer4, (-1, 8*32))\n",
        "\n",
        "flat = tf.layers.dropout(flat, rate=keep_prob_, training=tf_is_training) \n",
        "\n",
        "logits = tf.layers.dense(flat,1) \n",
        "cost=tf.losses.mean_squared_error(Y_,logits)\n",
        "global_step = tf.Variable(0)\n",
        " \n",
        "learning_rate = tf.train.exponential_decay(lr, global_step,200, 0.96, staircase=True) \n",
        "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost,global_step=global_step)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5qDkduaGnqq-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##1.2 E step"
      ]
    },
    {
      "metadata": {
        "id": "NryeWOnrjufP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def lamda(eita):\n",
        "    s=1/(1+np.exp(-eita))\n",
        "    lamda=(1/(2*eita))*(s-0.5)\n",
        "    return lamda\n",
        "\n",
        "\n",
        "def Estep(beta_old,sigma_old,Y,X,Z,epsilon):\n",
        "    N=Y.shape[0]\n",
        "    #L=X.shape[1]\n",
        "    K=Z.shape[1]\n",
        "    Sigma=(1/sigma_old)*(np.ones(K))\n",
        "    \n",
        "    for i in range(N):\n",
        "        Sigma=Sigma+2*lamda(np.sqrt(epsilon[i]))*Z[i,]#(np.outer(Z[i,],Z[i,]).diagonal())\n",
        "    \n",
        "    Sigma1=1/(Sigma)\n",
        "    mu=np.zeros(K)\n",
        "    for i in range(N):\n",
        "        mu=mu+Z[i,]-2*Y[i]*Z[i,]+4*lamda(np.sqrt(epsilon[i]))*(np.dot(X[i,],beta_old))*Z[i,]\n",
        "    p=-0.5*Sigma1*mu\n",
        "    list1=[p,Sigma1]\n",
        "    return list1\n",
        "beta_old=np.random.random(X.shape[1])\n",
        "sigma_old=1\n",
        "gamma_old=1\n",
        "b_old=np.append(beta_old,gamma_old)\n",
        "N=X.shape[0]\n",
        "epsilon=np.zeros(N)\n",
        "\n",
        "for i in range(N):\n",
        "  epsilon[i]=sigma_old*np.dot(Z[i,],Z[i,])+(np.dot(X[i,],beta_old))**2\n",
        "\n",
        "p,Sigma=Estep(beta_old,sigma_old,Y,X,Z,epsilon)#initialize E step\n",
        "epsilon_new=epsilon#updatew epsilon\n",
        "for i in range(N):\n",
        "    epsilon_new[i]=np.dot(Sigma,Z[i,])+(np.dot(p,Z[i,]))**2+2*(np.dot(X[i,],beta_old))*(np.dot(Z[i,],p))+(np.dot(X[i,],beta_old))**2\n",
        "g=-1000000000#lower bound"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Br_VLJYMm6Es",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##1.3 Functions for updating the cost function of CNN  and updating  beta, gamma and sigma"
      ]
    },
    {
      "metadata": {
        "id": "nPFeOtslRTyA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def y(beta_old,gamma_old,Y,X,Z,epsilon):\n",
        "    N=X.shape[0]\n",
        "    y_nn=np.zeros(N)\n",
        "    for i in range(N):\n",
        "        y_nn[i]=0.5/(lamda(np.sqrt(epsilon[i]))*gamma_old)*(Y[i]-0.5-2*lamda(np.sqrt(epsilon[i]))*(np.dot(X[i,],beta_old)+np.dot(Z[i,],p)))\n",
        "    return y_nn   \n",
        "        \n",
        "def bMstep(beta_old,sigma_old,Y,X,Z,epsilon,p,Sigma):\n",
        "    epsilon_new=epsilon\n",
        "    N=X.shape[0]\n",
        "    L=X.shape[1]\n",
        "    K=Z.shape[1]  \n",
        "    S=np.zeros((L,L))\n",
        "    M=np.zeros(L)\n",
        "    for i in range(N):\n",
        "        S=S+2*lamda(np.sqrt(epsilon_new[i]))*np.outer(X[i,],X[i,])\n",
        "        M=M+Y[i]*X[i,]-2*lamda(np.sqrt(epsilon_new[i]))*(np.dot(Z[i,],p))*X[i,]-0.5*X[i,]\n",
        "    beta_new=np.matmul(np.linalg.inv(S),M)\n",
        "    sigma_new=(np.dot(p,p)+np.sum(Sigma))/K\n",
        "    list3=[beta_new,sigma_new]\n",
        "    return list3        \n",
        "        \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FLDn3DUhg96C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##1.4 Funcitons for accuracy of VEM"
      ]
    },
    {
      "metadata": {
        "id": "gnu-gJIOg8Jb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def prediction(x,beta,p,Sigma,z):#  Ep_i\n",
        "    mu=np.dot(z,p)\n",
        "    sigma=np.dot(Sigma,z)# posterior mean and sigma of random effects\n",
        "    def w(u):#pi\n",
        "        b=1/(1+np.exp(-np.dot(x,beta)-u))\n",
        "        return b\n",
        "    W=np.zeros(2000)\n",
        "    for i in range(2000):\n",
        "        u=np.random.normal(mu, sigma, 1)# Monte carlo method\n",
        "        W[i]=w(u)\n",
        "    return np.mean(W)\n",
        "def accuracy(X,Y,Z,beta_old,p,Sigma,T=0.5):\n",
        "  N=X.shape[0]\n",
        "  acc=0\n",
        "  Y_P=np.zeros(N)\n",
        "  for i in range(N):\n",
        "    if prediction(X[i,],beta_old,p,Sigma,Z[i,])>T:\n",
        "      Y_P[i]=1\n",
        "    if Y_P[i]==Y[i]:\n",
        "      acc=acc+1\n",
        "      \n",
        "  return acc/N  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z350gmusFOiM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##1.5Perform the algorithm"
      ]
    },
    {
      "metadata": {
        "id": "zhDd_5zpRIpQ",
        "colab_type": "code",
        "outputId": "64037b64-454a-492f-fad9-42c687ce866c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1617
        }
      },
      "cell_type": "code",
      "source": [
        "sess=tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "    \n",
        "    \n",
        "N=Y.shape[0]\n",
        "L1=X.shape[1]\n",
        "K=Z.shape[1] \n",
        "    # Loop over epochs\n",
        "for e in range(epochs):\n",
        "          \n",
        "    \n",
        "   \n",
        "    #update cost and logits\n",
        "  epsilon=epsilon_new\n",
        "  Y_new=y(beta_old,gamma_old,Y,X,Z,epsilon)#  X , beta_old not x_com. b_old\n",
        "        #cost=tf.squre(Y_-logits)\n",
        "        \n",
        "  for u in range(100):\n",
        "  \n",
        "    sess.run(optimizer, feed_dict={inputs_ :  X_train, Y_: Y_new.reshape(Y_new.shape[0],1),  tf_is_training: True})#feed Y_:Y_neW\n",
        "       \n",
        "  logit,costs=sess.run([logits,cost], feed_dict={inputs_ :  X_train, Y_: Y_new.reshape(Y_new.shape[0],1),  tf_is_training: False})\n",
        "  print(costs)\n",
        "        \n",
        "  b_old=np.append(beta_old,gamma_old)\n",
        "  X_com=np.concatenate((X,logit),axis=1)\n",
        "  sigma=sigma_old\n",
        "  b_old,sigma_old=bMstep(b_old,sigma_old,Y,X_com,Z,epsilon,p,Sigma)\n",
        "  beta_old=b_old[0:L1]\n",
        "  gamma_old=b_old[-1]\n",
        "  g_old=g\n",
        "  g=-0.5*K*np.log(sigma_old)+0.5*np.sum(np.log(Sigma))#lower bound\n",
        "  for i in range(N):\n",
        "    g=g+Y[i]*(np.dot(Z[i,],p)+np.dot(X_com[i,],b_old))-lamda(np.sqrt(epsilon[i]))*(np.dot(Sigma,Z[i,])+(np.dot(p,Z[i,]))**2+2*(np.dot(X_com[i,],b_old))*(np.dot(Z[i,],p))+(np.dot(X_com[i,],b_old))**2-epsilon[i])-0.5*(np.dot(Z[i,],p))-0.5*(np.dot(X_com[i,],b_old))-0.5*np.sqrt(epsilon[i])+np.log(1/(1+np.exp(-np.sqrt(epsilon[i]))))\n",
        "        #if g。g_\n",
        "  if abs(g-g_old)<0.01:\n",
        "    break\n",
        "  if abs(sigma-sigma_old)<0.02:\n",
        "    break\n",
        "        #TEST ACCURACY\n",
        "        #Xtest =featuretest+1,Ytest=labeltest\n",
        "  logitstest=sess.run(logits, feed_dict={inputs_ :  X_test, Y_: labeltest,  tf_is_training: False})\n",
        "  X_comtest=np.concatenate((Xtest,logitstest),axis=1)\n",
        "  if (e % 5==0):\n",
        "    accn=accuracy(X_comtest[Ytest==0],Ytest[Ytest==0],Ztest[Ytest==0],b_old,p,Sigma)\n",
        "    accp=accuracy(X_comtest[Ytest>0],Ytest[Ytest>0],Ztest[Ytest>0],b_old,p,Sigma)\n",
        "    acc=accuracy(X_com,Y,Z,b_old,p,Sigma)\n",
        "    print(acc,accn,accp)\n",
        "        #E step\n",
        "  p,Sigma=Estep(b_old,sigma_old,Y,X_com,Z,epsilon)#initialize\n",
        "         #update epsilon\n",
        "  epsilon_new=epsilon\n",
        "  for i in range(N):\n",
        "    epsilon_new[i]=np.dot(Sigma,Z[i,])+(np.dot(p,Z[i,]))**2+2*(np.dot(X_com[i,],b_old))*(np.dot(Z[i,],p))+(np.dot(X_com[i,],b_old))**2\n",
        "  print(g,sigma_old)\n",
        "        #print(g)      "
      ],
      "execution_count": 0,
      
        }
      ]
    },
    {
      "metadata": {
        "id": "dDwbAqswC4nP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Save model"
      ]
    },
    {
      "metadata": {
        "id": "mDWPULiZCB7I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "saver = tf.train.Saver()\n",
        "saver.save(sess,\"model_test\")\n",
        "sess.close()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4kZqVaAfJvrk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sess=tf.Session()\n",
        "saver.restore(sess,\"model_test\")  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S6RzDKq0DBVk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## ROC curve"
      ]
    },
    {
      "metadata": {
        "id": "37C9Ou9Zogo7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "h_test_list1=[]# POSITIVE ACCUARACY\n",
        "n_test_list1=[]#NEGTIVE ACCURACY\n",
        "\n",
        "for i in range(50):\n",
        "  T=1-0.02*i\n",
        "  \n",
        "  \n",
        "  acn=accuracy(Xtest[Ytest==0],Ytest[Ytest==0],Ztest[Ytest==0],beta_old,p,Sigma,T)\n",
        "  acp=accuracy(Xtest[Ytest>0],Ytest[Ytest>0],Ztest[Ytest>0],beta_old,p,Sigma,T)\n",
        "  h_test_list1.append(acp)\n",
        "  n_test_list1.append(acn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h9kNQKKFTx9_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure()\n",
        "plt.xlim((0, 1))\n",
        "\n",
        "plt.ylim((0, 1))\n",
        "plt.plot(n_test_list1[0:50],  h_test_list1[0:50])                    \n",
        "#plt.scatter(n_test_list1[0:20], h_test_list1[0:20], marker='x')\n",
        "plt.ylabel('posive_acc')\n",
        "plt.xlabel('negtive_acc')\n",
        "\n",
        "plt.show()\n",
        "sess.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5obrTDz6F1sa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Sextion 2  Mixed logistic regression"
      ]
    },
    {
      "metadata": {
        "id": "6lInc96_5Hqd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2.1E step and M step"
      ]
    },
    {
      "metadata": {
        "id": "Zp5UGtg31o0_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def lamda(eita):\n",
        "    s=1/(1+np.exp(-eita))\n",
        "    lamda=(1/(2*eita))*(s-0.5)\n",
        "    return lamda\n",
        "\n",
        "\n",
        "def Estep(beta_old,sigma_old,Y,X,Z,epsilon):\n",
        "    N=Y.shape[0]\n",
        "    #L=X.shape[1]\n",
        "    K=Z.shape[1]\n",
        "    Sigma=(1/sigma_old)*(np.ones(K))\n",
        "    \n",
        "    for i in range(N):\n",
        "        Sigma=Sigma+2*lamda(np.sqrt(epsilon[i]))*Z[i,]#(np.outer(Z[i,],Z[i,]).diagonal())\n",
        "    \n",
        "    Sigma1=1/(Sigma)\n",
        "    mu=np.zeros(K)\n",
        "    for i in range(N):\n",
        "        mu=mu+Z[i,]-2*Y[i]*Z[i,]+4*lamda(np.sqrt(epsilon[i]))*(np.dot(X[i,],beta_old))*Z[i,]\n",
        "    p=-0.5*Sigma1*mu\n",
        "    list1=[p,Sigma1]\n",
        "    return list1\n",
        "\n",
        "def Mstep(beta_old,sigma_old,Y,X,Z,epsilon,p,Sigma):\n",
        "    epsilon_new=epsilon\n",
        "    N=Y.shape[0]\n",
        "    L=X.shape[1]\n",
        "    K=Z.shape[1]    \n",
        "    for i in range(N):\n",
        "        epsilon_new[i]=np.dot(Sigma,Z[i,])+(np.dot(p,Z[i,]))**2+2*(np.dot(X[i,],beta_old))*(np.dot(Z[i,],p))+(np.dot(X[i,],beta_old))**2\n",
        "    S=np.zeros((L,L))\n",
        "    M=np.zeros(L)\n",
        "    for i in range(N):\n",
        "        S=S+2*lamda(np.sqrt(epsilon_new[i]))*np.outer(X[i,],X[i,])\n",
        "        M=M+Y[i]*X[i,]-2*lamda(np.sqrt(epsilon_new[i]))*(np.dot(Z[i,],p))*X[i,]-0.5*X[i,]\n",
        "    beta_new=np.matmul(np.linalg.inv(S),M)\n",
        "    sigma_new=(np.dot(p,p)+np.sum(Sigma))/K\n",
        "    list2=[beta_new,sigma_new,epsilon_new]\n",
        "    return list2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_hNlfcKR5OV_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2.2excution"
      ]
    },
    {
      "metadata": {
        "id": "wavwX6u806gp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "N=X.shape[0]\n",
        "sigma_old=1\n",
        "beta_old=np.random.random(X.shape[1])\n",
        "\n",
        "\n",
        "epsilon=np.zeros(N)\n",
        "for i in range(N):\n",
        "    epsilon[i]=sigma_old*np.dot(Z[i,],Z[i,])+(np.dot(X[i,],beta_old))**2\n",
        "K=Z.shape[1] \n",
        "epochs=200\n",
        "g=-100000000\n",
        "for e in range(epochs):\n",
        "    p,Sigma=Estep(beta_old,sigma_old,Y,X,Z,epsilon)\n",
        "    beta_old,sigma_old,epsilon=Mstep(beta_old,sigma_old,Y,X,Z,epsilon,p,Sigma)\n",
        "    g_old=g\n",
        "    g=-0.5*K*np.log(sigma_old)+0.5*np.sum(np.log(Sigma))#lower bound\n",
        "    for i in range(N):\n",
        "        g=g+Y[i]*(np.dot(Z[i,],p)+np.dot(X[i,],beta_old))-lamda(np.sqrt(epsilon[i]))*(np.dot(Sigma,Z[i,])+(np.dot(p,Z[i,]))**2+2*(np.dot(X[i,],beta_old))*(np.dot(Z[i,],p))+(np.dot(X[i,],beta_old))**2-epsilon[i])-0.5*(np.dot(Z[i,],p))-0.5*(np.dot(X[i,],beta_old))-0.5*np.sqrt(epsilon[i])+np.log(1/(1+np.exp(-np.sqrt(epsilon[i]))))\n",
        "    #if g。g_\n",
        "    if abs(g-g_old)<0.01:\n",
        "      break\n",
        "    \n",
        "    print(g,sigma_old)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8X-ISO-J41Ou",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##2.3 ACCURACY"
      ]
    },
    {
      "metadata": {
        "id": "UJc37kAD4jXj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def prediction(x,beta,p,Sigma,z):#  pi\n",
        "    mu=np.dot(z,p)\n",
        "    sigma=np.dot(Sigma,z)# posterior mean and sigma of random effects\n",
        "    def w(u):#pi\n",
        "        b=1/(1+np.exp(-np.dot(x,beta)-u))\n",
        "        return b\n",
        "    W=np.zeros(2000)\n",
        "    for i in range(2000):\n",
        "        u=np.random.normal(mu, sigma, 1)# Monte carlo method\n",
        "        W[i]=w(u)\n",
        "    return np.mean(W)\n",
        "def accuracy(X,Y,Z,beta_old,p,Sigma,T):\n",
        "  N=X.shape[0]\n",
        "  acc=0\n",
        "  Y_P=np.zeros(N)\n",
        "  for i in range(N):\n",
        "    if prediction(X[i,],beta_old,p,Sigma,Z[i,])>T:\n",
        "      Y_P[i]=1\n",
        "    if Y_P[i]==Y[i]:\n",
        "      acc=acc+1\n",
        "      \n",
        "  return acc/N"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tsS2p23w5Cus",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##2.4 ROC"
      ]
    },
    {
      "metadata": {
        "id": "e9PZnohO-DyT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "h_test_list2=[]# POSITIVE ACCUARACY\n",
        "n_test_list2=[]#NEGTIVE ACCURACY\n",
        "\n",
        "for i in range(50):\n",
        "  T=1-0.02*i\n",
        "  \n",
        "  \n",
        "  acn=accuracy(Xtest[Ytest==0],Ytest[Ytest==0],Ztest[Ytest==0],beta_old,p,Sigma,T)\n",
        "  acp=accuracy(Xtest[Ytest>0],Ytest[Ytest>0],Ztest[Ytest>0],beta_old,p,Sigma,T)\n",
        "  h_test_list2.append(acp)\n",
        "  n_test_list2.append(acn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lXTNiq7bGGpK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Sectoin 3 CNN"
      ]
    },
    {
      "metadata": {
        "id": "gCuFwd0DXYYA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "def bn(inputsx,in_size,decay_rate,on_train):\n",
        "    fc_mean, fc_var = tf.nn.moments(\n",
        "\n",
        "                inputsx,\n",
        "\n",
        "                axes=[0],   \n",
        "            )\n",
        "    scale = tf.Variable(tf.ones([in_size]))\n",
        "\n",
        "    shift = tf.Variable(tf.zeros([in_size]))\n",
        "\n",
        "    epsilon = 0.001\n",
        "\n",
        "\n",
        "\n",
        "            # apply moving average for mean and var when train on batch\n",
        "\n",
        "    ema = tf.train.ExponentialMovingAverage(decay=decay_rate)\n",
        "\n",
        "    def mean_var_with_update():\n",
        "        ema_apply_op = ema.apply([fc_mean, fc_var])\n",
        "        with tf.control_dependencies([ema_apply_op]):\n",
        "            return tf.identity(fc_mean), tf.identity(fc_var)\n",
        "\n",
        "    mean, var = tf.cond(on_train,    # on_train 的值是 True/False\n",
        "            mean_var_with_update,   # 如果是 True, 更新 mean/var\n",
        "            lambda: (               # 如果是 False, 返回之前 fc_mean/fc_var 的Moving Average\n",
        "                ema.average(fc_mean), \n",
        "                ema.average(fc_var)\n",
        "                )    \n",
        "            )\n",
        "    bn_learner = tf.nn.batch_normalization(inputsx, mean, var, shift, scale, epsilon)\n",
        "    return bn_learner\n",
        "w=1#weight\n",
        "n_classes = 1\n",
        "n_channels = 1\n",
        "batch_size = 600       # Batch size\n",
        "seq_len =   256     # Number   time sequence\n",
        "lr = 0.0001\n",
        "epochs = 1500\n",
        "keep_prob_=0.5\n",
        "de_rate=0.5\n",
        "K_size=16#kernal size\n",
        "inputs_ = tf.placeholder(tf.float32, [None, seq_len, n_channels], name = 'inputs')\n",
        "labels_ = tf.placeholder(tf.float32, [None, n_classes], name = 'labels')\n",
        "feature_ = tf.placeholder(tf.float32, [None, 8], name = 'features')\n",
        "tf_is_training = tf.placeholder(tf.bool, None)  # to control dropout when training and testing\n",
        "def layer(inputss,n_out):\n",
        "    conv1 = tf.layers.conv1d(inputs=inputss, filters=n_out, kernel_size=K_size, strides=1, \n",
        "                             padding='same', activation = None)\n",
        "    bn_layer1=bn(conv1,n_out,de_rate,tf_is_training)\n",
        "    relu1=tf.nn.relu(bn_layer1)\n",
        "    max_pool_1 = tf.layers.max_pooling1d(inputs=relu1, pool_size=K_size, strides=2, padding='same')\n",
        "    return max_pool_1\n",
        "layer1=layer(inputs_,8)\n",
        "layer2=layer(layer1,8)\n",
        "layer3=layer(layer2,16)  \n",
        "layer4=layer(layer3,16) \n",
        "#layer5=layer(layer4,32)\n",
        "#layer6=layer(layer5,32)\n",
        "#layer7=layer(layer6,64)\n",
        "flat = tf.reshape(layer5, (-1,16*16))\n",
        "\n",
        "flat = tf.layers.dropout(flat, rate=keep_prob_, training=tf_is_training) \n",
        "nfeature=tf.concat([flat,feature_],1)\n",
        "logits = tf.layers.dense(nfeature,1)   #\n",
        "prediction=tf.nn.sigmoid(logits)\n",
        "#prediction=tf.nn.softmax(logits)#4 class\n",
        "cost = tf.reduce_mean(tf.nn.weighted_cross_entropy_with_logits(targets=labels_,logits=logits,pos_weight=w))\n",
        "#cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels_))#4 classes\n",
        "global_step = tf.Variable(0)\n",
        " \n",
        "learning_rate = tf.train.exponential_decay(lr, global_step, 101, 0.96, staircase=True) \n",
        "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost,global_step=global_step)\n",
        "\n",
        "# Calculate the correct predictions\n",
        "correct_prediction = tf.to_float(tf.greater(prediction, 0.5))\n",
        "accuracy = tf.reduce_mean(tf.to_float(tf.equal(labels_, correct_prediction)))\n",
        "accc=tf.equal(labels_, correct_prediction)\n",
        "N1=tf.reduce_sum(labels_)\n",
        "N=tf.reduce_sum(tf.ones_like(labels_))\n",
        "N0=N-N1\n",
        "mask_1=tf.equal(labels_,tf.ones_like(labels_))\n",
        "accp=tf.reduce_mean(tf.to_float(tf.boolean_mask(accc, mask_1)))\n",
        "mask_0=tf.equal(labels_,tf.zeros_like(labels_))\n",
        "accn=tf.reduce_mean(tf.to_float(tf.boolean_mask(accc, mask_0)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3ujV65EjiEBk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "    #iteration=1\n",
        "   \n",
        "    # Loop over epochs\n",
        "for e in range(epochs):\n",
        "        \n",
        "        # Loop over batches\n",
        "        \n",
        "           \n",
        "            #loss, _  =sess.run([cost, optimizer], feed_dict={inputs_ : X_train, labels_: label, feature_: feature, tf_is_training: True})\n",
        "  sess.run([cost, optimizer], feed_dict={inputs_ :  X_train, labels_: labeltrain,feature_: featuretrain,  tf_is_training: True})\n",
        "            \n",
        "            #, feature_:featuretrain\n",
        "            # Print at each 5 iters\n",
        "  if (e % 10 == 0):\n",
        "    acc=sess.run(accuracy, feed_dict={inputs_ : X_train, labels_: labeltrain, feature_: featuretrain, tf_is_training: False})\n",
        "                #acc=sess.run(accuracy, feed_dict={inputs_ : X_train, labels_: label, feature_: feature, tf_is_training: False})\n",
        "    acp,acn,acctest=sess.run([accp,accn,accuracy], feed_dict={inputs_ : X_test, labels_: labeltest, feature_: featuretest, tf_is_training: False})\n",
        "    print(\"Epoch: {}/{}\".format(e, epochs),\n",
        "          \"Train acc: {:6f}\".format(acc),\n",
        "          \"Test acc: {:.6f}\".format(acctest),\n",
        "          \"Test accp: {:.6f}\".format(acp),\n",
        "          \"Test accn: {:.6f}\".format(acn))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "42NrsCk0_qvd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def ROC(T):\n",
        "  \n",
        "  correct_prediction = tf.to_float(tf.greater(prediction, T))\n",
        "\n",
        "  accuracy = tf.reduce_mean(tf.to_float(tf.equal(labels_, correct_prediction)))  \n",
        "  \n",
        "  accc=tf.equal(labels_, correct_prediction)\n",
        "  N1=tf.reduce_sum(labels_)\n",
        "  N=tf.reduce_sum(tf.ones_like(labels_))\n",
        "  N0=N-N1\n",
        "  mask_1=tf.equal(labels_,tf.ones_like(labels_))\n",
        "  accp=tf.reduce_mean(tf.to_float(tf.boolean_mask(accc, mask_1)))\n",
        "  mask_0=tf.equal(labels_,tf.zeros_like(labels_))\n",
        "  accn=tf.reduce_mean(tf.to_float(tf.boolean_mask(accc, mask_0)))\n",
        "  acp,acn,acctest=sess.run([accp,accn,accuracy], feed_dict={inputs_ : X_test, labels_: labeltest, feature_: featuretest, tf_is_training: False})\n",
        "  \n",
        "  return [acp,acn]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GLTk1nKAAC_M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "h_test_list3=[]# POSITIVE ACCUARACY\n",
        "n_test_list3=[]#NEGTIVE ACCURACY\n",
        "\n",
        "for i in range(50):\n",
        "  T=1-0.02*i\n",
        "  acp,acn=ROC(T)\n",
        "  h_test_list3.append(acp)\n",
        "  n_test_list3.append(acn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vG4f9gfYAUBs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "plt.xlim((0, 1))\n",
        "\n",
        "plt.ylim((0, 1))\n",
        "l1,=plt.plot(n_test_list1[0:50],  h_test_list1[0:50])  \n",
        "#l2,=plt.plot(n_test_list2[0:50],  h_test_list2[0:50])  \n",
        "#plt.scatter(n_test_list3[0:50], h_test_list3[0:50], marker='x')\n",
        "l3,=plt.plot(n_test_list3[0:50],  h_test_list3[0:50])    \n",
        "plt.legend(handles=[l1,l3], labels=['CNN_VEM',\"CNN\"],  loc='best')\n",
        "plt.ylabel('posive_acc')\n",
        "plt.xlabel('negtive_acc')\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LEhfEFPGCAPz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sess.close()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
